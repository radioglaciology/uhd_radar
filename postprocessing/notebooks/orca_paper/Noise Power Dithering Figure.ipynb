{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "client = Client(n_workers=1,\n",
    "                threads_per_worker=4,\n",
    "                memory_limit='16GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import time\n",
    "import os\n",
    "\n",
    "import dask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import scipy.constants\n",
    "import scipy\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "import processing_dask as pr\n",
    "import plot_dask\n",
    "\n",
    "sys.path.append(\"../../../preprocessing/\")\n",
    "from generate_chirp import generate_chirp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefix = \"/media/thomas/Extreme SSD/orca_paper_data_files/phase_noise/b205/20240222_203345\"\n",
    "\n",
    "#prefix = \"/Volumes/Extreme SSD/orca_paper/20240226_105437\" # no phase dithering, no LO offset\n",
    "#prefix = \"/Volumes/Extreme SSD/orca_paper/20240226_105916\" # yes phase dithering, no LO offset\n",
    "#prefix = \"/Volumes/Extreme SSD/orca_paper/20240226_110410\" # no phase dithering, software LO offset of 12.5 MHz\n",
    "#prefix = \"/Volumes/Extreme SSD/orca_paper/20240226_110948\" # yes phase dithering, software LO offset of 12.5 MHz\n",
    "\n",
    "prefix = \"/Volumes/Extreme SSD/orca_paper_data_files/dithering/b205/20240226_225223\" # no phase dithering, software LO offset of 12.5 MHz\n",
    "\n",
    "#zero_sample_idx = 63 # X310, fs = 50 MHz\n",
    "zero_sample_idx = 159\n",
    "\n",
    "dielectric_constant = 2.2957 # ice (air = 1, 66% velocity coax = 2.2957)\n",
    "sig_speed = scipy.constants.c / np.sqrt(dielectric_constant)\n",
    "\n",
    "zarr_path = pr.save_radar_data_to_zarr(prefix)\n",
    "\n",
    "zarr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = xr.open_zarr(zarr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirp_ts, chirp = generate_chirp(raw.config)\n",
    "\n",
    "compressed = pr.pulse_compress(raw, chirp,\n",
    "                               fs=raw.config['GENERATE']['sample_rate'],\n",
    "                               zero_sample_idx=zero_sample_idx,\n",
    "                               signal_speed=sig_speed).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pulse compressed data to location\n",
    "#zarr_base_location = \"/Volumes/Extreme SSD/orca_paper/\"\n",
    "zarr_base_location = \"/Volumes/Extreme SSD/orca_paper_data_files/dithering/b205\"\n",
    "compressed_zarr_path = os.path.join(zarr_base_location, raw.basename + \"_pulsecompressed.zarr\")\n",
    "print(\"Writing pulse compressed data to: \", compressed_zarr_path)\n",
    "\n",
    "compressed.to_zarr(compressed_zarr_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = xr.open_zarr(\"/Volumes/Extreme SSD/orca_paper_data_files/dithering/b205/20240226_225223_pulsecompressed.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks = [1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "ts = stacks\n",
    "\n",
    "noise_start_distance_1way = 1000 # m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Floor Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_stack_t = np.nan * np.zeros_like(ts)\n",
    "actual_stack_n = np.zeros_like(ts, dtype=int)\n",
    "\n",
    "# Statistics to compute\n",
    "stack_noise_var = np.nan * np.zeros_like(ts)\n",
    "stack_noise_mean = np.nan * np.zeros_like(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t_idx, t in enumerate(ts):\n",
    "    if not np.isnan(stack_noise_mean[t_idx]):\n",
    "        continue # Skip if already computed (in case of interruption and restart)\n",
    "    \n",
    "    timestamp = time.time() # Track computation time \n",
    "\n",
    "    actual_stack_n[t_idx] = t\n",
    "    actual_stack_t[t_idx] = actual_stack_n[t_idx] * raw.attrs['config']['CHIRP']['pulse_rep_int'] # TODO: Account for errors?\n",
    "    print(f\"[{t_idx+1}/{len(ts)}] \\tt={actual_stack_t[t_idx]} \\tn_stack={actual_stack_n[t_idx]}\")\n",
    "    \n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "\n",
    "        stacked = pr.stack(compressed, actual_stack_n[t_idx])\n",
    "        compressed_pwr = xr.apply_ufunc(lambda x: np.abs(x)**2, stacked, dask='parallelized').chunk(\"auto\")\n",
    "        \n",
    "        noise_pwr = compressed_pwr[\"radar_data\"].where((compressed_pwr.reflection_distance > noise_start_distance_1way)).dropna('travel_time').chunk(\"auto\")\n",
    "        \n",
    "        stack_noise_var[t_idx] = noise_pwr.var(dim=\"travel_time\").mean().compute().item()\n",
    "        stack_noise_mean[t_idx] = noise_pwr.mean().compute().item()\n",
    "\n",
    "        \n",
    "    print(f\"Completed in {time.time() - timestamp} seconds from {len(noise_pwr)} stacked pulses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_noise_var, ax_noise_mean) = plt.subplots(2, 1, figsize=(10, 20))\n",
    "\n",
    "ax_noise_var.scatter(actual_stack_n, stack_noise_var)\n",
    "ax_noise_var.set_title(\"Noise Variance\")\n",
    "ax_noise_var.loglog()\n",
    "ax_noise_var.grid()\n",
    "\n",
    "ax_noise_mean.scatter(actual_stack_n, stack_noise_mean)\n",
    "ax_noise_mean.set_title(\"Noise Mean\")\n",
    "ax_noise_mean.loglog()\n",
    "ax_noise_mean.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"outputs/{raw.basename}-noise-stats.pickle\", \"wb\") as f:\n",
    "    pickle.dump({'n_stacks': actual_stack_n, 'stack_times': actual_stack_t, 'stack_noise_var': stack_noise_var, 'stack_noise_mean': stack_noise_mean, 'prefix': raw.prefix}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprinkles",
   "language": "python",
   "name": "sprinkles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
